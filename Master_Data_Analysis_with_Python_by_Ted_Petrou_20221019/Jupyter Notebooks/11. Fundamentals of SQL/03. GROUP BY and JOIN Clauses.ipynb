{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f954a3c",
   "metadata": {},
   "source": [
    "# GROUP BY and JOIN Clauses\n",
    "\n",
    "In this chapter, we continue with the SQL SELECT statement by learning the GROUP BY and JOIN clauses. Let's recreate the connection string and read in all of the tables as pandas DataFrames from the healthcare database again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e570112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CS = 'sqlite:///../data/databases/healthcare.db'\n",
    "patient = pd.read_sql('patient', CS)\n",
    "doctor = pd.read_sql('doctor', CS)\n",
    "clinic = pd.read_sql('clinic', CS)\n",
    "procedure = pd.read_sql('procedure', CS)\n",
    "appointment = pd.read_sql('appointment', CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc94d68",
   "metadata": {},
   "source": [
    "## The GROUP BY clause\n",
    "\n",
    "The GROUP BY clause works similarly to the `groupby` DataFrame method. Unique values in the provided column form independent groups. Like pandas, an aggregating function must be used to return a single result for each group. The same components (**grouping column**, **aggregating column**, and **aggregating function**) are used with the GROUP BY clause. Here, the grouping column is `major_category`, there is no aggregating column as we are just finding the size of each group, and the aggregating function is `count`. Note that the grouping columns must appear in the SELECT clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56eb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, count(*) AS size\n",
    "FROM procedure\n",
    "GROUP BY major_category\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de017a",
   "metadata": {},
   "source": [
    "Replicate in pandas with the `groupby` `size` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41373d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure.groupby('major_category').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50d660",
   "metadata": {},
   "source": [
    "Any number of aggregations can be done simultaneously for each group. Here, we compute summary statistics on cost. The `round` function is used to round the average cost to the nearest 10 cents. You may be wondering why the `round` function can be used when its not an aggregating function. It is applied after the `avg` function has taken the aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, \n",
    "       count(*) AS size, \n",
    "       count(cost) AS non_null_cost,\n",
    "       min(cost) AS min_cost,\n",
    "       max(cost) AS max_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       sum(cost) AS total_cost\n",
    "FROM procedure\n",
    "GROUP BY major_category\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406e500",
   "metadata": {},
   "source": [
    "In pandas, rename the aggregated columns within the `agg` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(procedure.groupby('major_category')['cost']\n",
    "          .agg(size='size', \n",
    "               non_null_cost='count', \n",
    "               min_cost='min',\n",
    "               max_cost='max', \n",
    "               avg_cost='mean', \n",
    "               total_cost='sum')\n",
    "          .round({'avg_cost': 1})\n",
    "          .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174d1dd",
   "metadata": {},
   "source": [
    "### Grouping by multiple columns\n",
    "\n",
    "Separate columns after the GROUP BY clause to group by multiple columns. Here, unique combinations of `major_category` and `minor_category` form groups. We also aggregate both `cost` and `procedure_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, minor_category,\n",
    "       count(cost) AS non_null_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       min(procedure_id) as min_procedure_id,\n",
    "       max(procedure_id) as max_procedure_id\n",
    "FROM procedure\n",
    "GROUP BY major_category, minor_category\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33873373",
   "metadata": {},
   "source": [
    "With pandas, the grouping columns are placed in a list and the `agg` method must now use a tuple to specify both the aggregating column and aggregating function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(procedure.groupby(['major_category', 'minor_category'])\n",
    "          .agg(non_null_cost=('cost', 'count'),\n",
    "               avg_cost=('cost', 'mean'),\n",
    "               min_procedure_id=('procedure_id', 'min'),\n",
    "               max_procedure_id=('procedure_id', 'max'))\n",
    "          .round({'avg_cost': 1})\n",
    "          .reset_index()\n",
    "          .head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bad4b6",
   "metadata": {},
   "source": [
    "### Filtering before grouping\n",
    "\n",
    "The WHERE clause filters the data before it is grouped. Here, we filter out all the rows with cost less than 300 and then perform the same grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, minor_category,\n",
    "       count(cost) AS non_null_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       min(procedure_id) as min_procedure_id,\n",
    "       max(procedure_id) as max_procedure_id\n",
    "FROM procedure\n",
    "WHERE cost < 300\n",
    "GROUP BY major_category, minor_category\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac56f58",
   "metadata": {},
   "source": [
    "With pandas, use the `query` method before calling `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846de1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(procedure.query('cost < 300')\n",
    "          .groupby(['major_category', 'minor_category'])\n",
    "          .agg(non_null_cost=('cost', 'count'),\n",
    "               avg_cost=('cost', 'mean'),\n",
    "               min_procedure_id=('procedure_id', 'min'),\n",
    "               max_procedure_id=('procedure_id', 'max'))\n",
    "          .round({'avg_cost': 1})\n",
    "          .reset_index()\n",
    "          .head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814d79f",
   "metadata": {},
   "source": [
    "### Filtering after grouping with the HAVING subclause\n",
    "\n",
    "The HAVING subclause cannot be used on its own and must immediately proceed the GROUP BY clause. Place a boolean condition to the right of it using the columns created from the grouping. Here, we filter for groups that have an average cost between 620 and 640. The WHERE and HAVING clauses are very similar - the former filters the data before the grouping and the latter after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713074cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, minor_category,\n",
    "       count(cost) AS non_null_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       min(procedure_id) as min_procedure_id,\n",
    "       max(procedure_id) as max_procedure_id\n",
    "FROM procedure\n",
    "GROUP BY major_category, minor_category\n",
    "HAVING avg_cost BETWEEN 620 AND 640\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b07cc1",
   "metadata": {},
   "source": [
    "Replicate by calling the `query` method after the `groupby` method in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22988af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(procedure.groupby(['major_category', 'minor_category'])\n",
    "          .agg(non_null_cost=('cost', 'count'),\n",
    "               avg_cost=('cost', 'mean'),\n",
    "               min_procedure_id=('procedure_id', 'min'),\n",
    "               max_procedure_id=('procedure_id', 'max'))\n",
    "          .round({'avg_cost': 1})\n",
    "          .query('620 <= avg_cost <= 640')\n",
    "          .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887b79e",
   "metadata": {},
   "source": [
    "You can filter both before and after the grouping by providing WHERE and HAVING clauses. Here, we filter for procedures with a major category of either \"Surgery\" or \"Radiology\" and cost of less than 300. After grouping, we filter for groups with more than 50 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b546a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, minor_category,\n",
    "       count(cost) AS non_null_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       min(procedure_id) as min_procedure_id,\n",
    "       max(procedure_id) as max_procedure_id\n",
    "FROM procedure \n",
    "WHERE major_category in (\"Surgery\", \"Radiology\") and cost < 300\n",
    "GROUP BY major_category, minor_category\n",
    "HAVING non_null_cost > 50\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dff14",
   "metadata": {},
   "source": [
    "With pandas, call the `query` method before and after the `groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "(procedure.query('major_category in (\"Surgery\", \"Radiology\") and cost < 300')\n",
    "          .groupby(['major_category', 'minor_category'])\n",
    "          .agg(non_null_cost=('cost', 'count'),\n",
    "               avg_cost=('cost', 'mean'),\n",
    "               min_procedure_id=('procedure_id', 'min'),\n",
    "               max_procedure_id=('procedure_id', 'max'))\n",
    "          .round({'avg_cost': 1})\n",
    "          .query('non_null_cost > 50')\n",
    "          .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a57288",
   "metadata": {},
   "source": [
    "## Ordering after grouping\n",
    "\n",
    "The ORDER BY clause executes after the GROUP BY and HAVING clauses have finished aggregating and filtering the data. Here, we find all groups with an average cost above 600 and then return the ones with the most known procedure costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT major_category, minor_category,\n",
    "       count(cost) AS non_null_cost,\n",
    "       round(avg(cost), 1) AS avg_cost,\n",
    "       max(procedure_id) as max_procedure_id\n",
    "FROM procedure\n",
    "GROUP BY major_category, minor_category\n",
    "HAVING avg_cost > 600\n",
    "ORDER BY non_null_cost DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb3237",
   "metadata": {},
   "source": [
    "With pandas, call `sort_values` after the `groupby` and `query `methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(procedure.groupby(['major_category', 'minor_category'])\n",
    "          .agg(non_null_cost=('cost', 'count'),\n",
    "               avg_cost=('cost', 'mean'),\n",
    "               max_procedure_id=('procedure_id', 'max'))\n",
    "          .round({'avg_cost': 1})\n",
    "          .query('avg_cost > 600')\n",
    "          .sort_values('non_null_cost', ascending=False)\n",
    "          .reset_index()\n",
    "          .head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf91c05",
   "metadata": {},
   "source": [
    "### Grouping by calculated columns\n",
    "\n",
    "It's possible to group by columns not directly in the table. Here, we use the modulus operator to find the last digit of each `procedure_id` and use it as the grouping column. We then find the average cost and count of this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14660b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT \n",
    "    procedure_id % 10 as last_procedure_id_digit, \n",
    "    round(avg(cost), 1) as avg_cost, \n",
    "    count(*) as ct\n",
    "FROM procedure\n",
    "GROUP BY last_procedure_id_digit\n",
    "\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4cd9e",
   "metadata": {},
   "source": [
    "In pandas, the special grouping column must be created as a separate Series beforehand. Setting the `name` attribute of the Series will make it so that it used as the column name after the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f77d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = procedure['procedure_id'] % 10\n",
    "s.name = 'last_procedure_id_digit'\n",
    "(procedure.groupby(s)['cost']\n",
    "          .agg(avg_cost='mean',\n",
    "               ct='count')\n",
    "          .round({'avg_cost': 1})\n",
    "          .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d3017",
   "metadata": {},
   "source": [
    "## The JOIN subclause\n",
    "\n",
    "The JOIN subclause must appear directly after the FROM clause and is used to join the rows of two tables together based on a boolean condition. The generic syntax is as follows:\n",
    "\n",
    "`FROM left_table AS a JOIN right_table AS b ON a.column = b.column`\n",
    "\n",
    "Each table is provided an **alias** with AS which allows us to reference that table with the alias instead of the entire table name. This helps shorten the syntax. The condition on how the rows are joined is provided after the ON keyword. The simplest case is when a single value in the left table's row is equal to a single value in the right table's row.\n",
    "\n",
    "It's important to have the database diagram available to understand how to join tables. The diagram will show you which columns join with which tables. As discussed in the Joining Data part, there are three major types of joins, an inner join, a left join, and a full join. Inner joins keep rows where the condition after the ON keyword evaluates as true. An inner join occurs by default when using the keyword JOIN, but you can use INNER JOIN for clarity. \n",
    "\n",
    "Below, we create an inner join between the appointment table and doctor table joining them on column `doctor_id`. From the database diagram, each row in the appointment table should align with exactly one row in the doctor table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64c895",
   "metadata": {},
   "source": [
    "Note that the alias `a` refers to the appointment table and that the alias `d` refers to the doctor table. Aliases can be any length are are typically one or just a few characters in length. Aliases are not necessary and the statement could be rewritten without them to be:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM appointment\n",
    "    INNER JOIN doctor ON appointment.doctor_id = doctor.doctor_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c356c29",
   "metadata": {},
   "source": [
    "The `merge` method duplicates this join. Provide it the joining column and the type of join. The result does not preserve the original order of the left table like in SQL so the `sort_values` method is called to revert it to its original ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450ff03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(appointment.merge(doctor, on='doctor_id', how='inner')\n",
    "           .sort_values('appointment_id').head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8932ecf",
   "metadata": {},
   "source": [
    "### Use aliases to select specific columns\n",
    "\n",
    "Notice the SQL result has the `doctor_id` column twice, while with pandas, it appears once. Since we used `SELECT *`, all of the columns from all of the tables are returned. We can select specific columns from each table using each table's alias. Here, we select all columns from the left table and three of the columns from the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT a.*, d.first_name, d.last_name, d.specialty\n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acb8e5",
   "metadata": {},
   "source": [
    "### Other clauses when joining\n",
    "\n",
    "Joining of the tables happens before any of the other clauses. Here, we filter for a specific clinic and patient after finding the doctor's specialty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdff436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT a.appointment_id, a.clinic_id, a.date, d.specialty\n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "WHERE clinic_id = 4 and patient_id = 100\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4aa930",
   "metadata": {},
   "source": [
    "In pandas, use the `query` method after the `merge` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a901f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(appointment.merge(doctor, on='doctor_id', how='inner')\n",
    "           .sort_values('appointment_id')\n",
    "           .query('clinic_id == 4 and patient_id == 100')\n",
    "           [['appointment_id', 'clinic_id', 'date', 'specialty']]\n",
    "            .head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f906ac1",
   "metadata": {},
   "source": [
    "The number of appointments by doctor specialty can be retrieved by grouping after joining the tables together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT d.specialty, count(*) as num_appointments\n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "GROUP BY d.specialty\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b1259",
   "metadata": {},
   "source": [
    "In pandas, we call the `groupby` method after `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67863680",
   "metadata": {},
   "outputs": [],
   "source": [
    "(appointment.merge(doctor, on='doctor_id', how='inner')\n",
    "            .groupby('specialty').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b393c",
   "metadata": {},
   "source": [
    "Here, we find the number of appointments by specialty in clinics 3 and 4. We then sort the results from greatest to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9428b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT d.specialty, count(*) as num_appointments\n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "WHERE clinic_id in (3, 4)\n",
    "GROUP BY d.specialty\n",
    "ORDER BY num_appointments DESC\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367113f",
   "metadata": {},
   "source": [
    "Add the `query` method after `merge` and then use `sort_values` as the last command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "(appointment.merge(doctor, on='doctor_id', how='inner')\n",
    "            .query('clinic_id in (3, 4)')\n",
    "            .groupby('specialty').size()\n",
    "            .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74d581",
   "metadata": {},
   "source": [
    "### Joining more than two tables\n",
    "\n",
    "Any number of tables may be joined together by adding more JOIN subclauses. Here, we join the three other tables to the appointment table selecting one or two columns from each table. Each row has four equality conditions that must be satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT a.appointment_id,\n",
    "       a.date,\n",
    "       d.specialty AS doctor_specialty, \n",
    "       c.name AS clinic_name,\n",
    "       p.first_name as patient_first_name,\n",
    "       pr.major_category,\n",
    "       pr.cost      \n",
    "FROM appointment AS a\n",
    "    INNER JOIN doctor AS d ON a.doctor_id = d.doctor_id\n",
    "    INNER JOIN clinic AS c ON a.clinic_id = c.clinic_id\n",
    "    INNER JOIN patient AS p ON a.patient_id = p.patient_id\n",
    "    INNER JOIN procedure AS pr ON a.procedure_id = pr.procedure_id\n",
    "LIMIT 3\n",
    "\"\"\"\n",
    "pd.read_sql(sql, CS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96419ea5",
   "metadata": {},
   "source": [
    "A similar result in pandas can be achieved by first selecting the desired columns for each table as separate DataFrames and then passing them to the `merge` method. The appointment table needs to be have all of its foreign key columns before calling `merge`. They are then dropped after all the joins have completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc492bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = doctor[['doctor_id', 'specialty']]\n",
    "c = clinic[['clinic_id', 'name']]\n",
    "p = patient[['patient_id', 'first_name']]\n",
    "pr = procedure[['procedure_id', 'major_category', 'cost']]\n",
    "(appointment.merge(d, on='doctor_id')\n",
    "            .merge(c, on='clinic_id')\n",
    "            .merge(p, on='patient_id')\n",
    "            .merge(pr, on='procedure_id')\n",
    "            .drop(columns = ['patient_id', 'clinic_id', 'doctor_id', 'procedure_id'])\n",
    "            .head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74eb655",
   "metadata": {},
   "source": [
    "This example highlights the major differences between a declarative language like SQL and a procedural language like Python. In SQL, the entire statement is read by the execution engine before it runs. It sees what the final result needs to be - the number of tables to join together, the specific columns from each table, etc... \n",
    "\n",
    "In Python, every statement runs in the order that it appears. The very first `merge` from above does not know that there will be calls to other `merge` methods below it. SQL has a big advantage, in this instance, by being able to see and understand the entire statement before its execution. In Python, each statement is independent of the next, so no planning can occur. The multiple join statement above runs much faster in SQL than in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e338016",
   "metadata": {},
   "source": [
    "### Left joins\n",
    "\n",
    "In addition to all of the rows of an inner join, a left join includes all rows in the left table that have no matches in the right table. All of these rows without a match will have NULL as the value for the columns in the right table.\n",
    "\n",
    "A few of the doctors in the doctor table do not appear in the appointment table. Let's perform a left join on the doctor's table with the appointment and assign the result to the variable name `df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04182dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM doctor AS d\n",
    "    LEFT JOIN appointment AS a ON d.doctor_id = a.doctor_id\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, CS)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b67019e",
   "metadata": {},
   "source": [
    "This results in 9,124 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d9f4c",
   "metadata": {},
   "source": [
    "But the appointment table has three less rows in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c28e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(appointment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e8b87",
   "metadata": {},
   "source": [
    "We can find the three doctors who do not appear appear in the appointment table by filtering for them in the WHERE clause. We test that the doctor_id column in the appointment table is NULL, and therefore did not have a match. A left join keeps these doctors in the result, even though their doctor_id does not appear in the appointment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e48555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM doctor AS d\n",
    "    LEFT JOIN appointment AS a ON d.doctor_id = a.doctor_id\n",
    "WHERE a.doctor_id is NULL\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, CS)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f28bc",
   "metadata": {},
   "source": [
    "These three doctors would not appear if an INNER JOIN were used. Here, we change the type of join to confirm the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0407c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM doctor AS d\n",
    "    INNER JOIN appointment AS a ON d.doctor_id = a.doctor_id\n",
    "WHERE a.doctor_id is NULL\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, CS)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd64f1",
   "metadata": {},
   "source": [
    "Set the `how` parameter to `'left'` in pandas and then filter using boolean selection to find the rows that have missing values for the appointment table columns. You'll discover the same doctors absent from the appointment table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee21d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doctor.merge(appointment, on='doctor_id', how='left')\n",
    "filt = df['appointment_id'].isna()\n",
    "df[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268448",
   "metadata": {},
   "source": [
    "## Right and Full joins\n",
    "\n",
    "Unfortunately, SQLite does not provide right or full joins like most other RDBMS's. A right join can mostly be replicated by switching the order of the joining tables and performing a left join. A full join requires the use of the UNION clause, which stacks unique records of tables one on top of the other similar to the `pd.concat` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ae806",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "All of these exercises use the Chinook database with SQL SELECT statements to answer each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298e14d",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Find the grand total of invoices by billingcountry. Order the results by this total from greatest to least.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db0305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dcb79e8",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Find the count, min, max, and avg milliseconds by genreid in the tracks table. Convert the milliseconds to minutes. Order the results by count descending.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8344ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417b5939",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Using the invoice_items table, count the times each trackid and invoiceid combination appear. This number should be one, as an invoice should not have multiple instances of the same trackid. Can you verify that there is in fact at most one?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be249a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e93e0b62",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Calculate the total revenue of each track using the invoice_items table. Return the top five tracks by revenue.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da097bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1ceebfc",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Create a table with the track name and genre name (not genreid).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab58c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f669be94",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Create a table with the track name, genre name, album title, and artist title. You will need to join four tables together.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5052d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582fd071",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">For tracks less than two minutes in length, count the occurrence of each media type. Make sure to use the media type name.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fb2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
