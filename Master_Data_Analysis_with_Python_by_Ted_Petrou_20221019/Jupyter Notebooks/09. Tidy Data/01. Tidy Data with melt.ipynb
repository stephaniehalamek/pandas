{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data with `melt`\n",
    "\n",
    "Up through this point of the book, we have yet to change the structure or do any preprocessing before computing results with our datasets. We immediately began generating results and answering questions. Producing results is typically not the first step of a data analysis. The vast majority of real-life datasets will need some amount of inspection and preprocessing first. And in some cases, the entire project will just be about cleaning the data so that it can be further processed by someone else. \n",
    "\n",
    "This chapter will use many ideas first formulated by [Edgar Codd][0] in the 1960s and 1970s, before being simplified into terms that beginning data analysts can understand by [Hadley Wickham]. The central idea of this chapter is **Tidy data**, is a structure of data that makes doing data analysis easier.\n",
    "\n",
    "## Tidy data and Lego\n",
    "\n",
    "I like to analogize tidy data to Lego, one of the most popular toys of all time.\n",
    "\n",
    "There's an infamous data science saying that goes something like this: \"data scientists spend 80% of their time cleaning data and the other 20% complaining about cleaning the data.\"\n",
    "\n",
    "[0]: https://en.wikipedia.org/wiki/Edgar_F._Codd\n",
    "[1]: https://en.wikipedia.org/wiki/Hadley_Wickham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Data\n",
    "\n",
    "Tidy data is a term coined by Hadley Wickham, the creator of many popular R packages, to describe a specific **structure** of data that makes analysis easier. It is recommended that you read [his paper][1] to get a complete understanding. A dataset is tidy when:\n",
    "\n",
    "1. Each variable forms a column\n",
    "2. Each observation forms a row\n",
    "3. Each type of observational unit forms a table\n",
    "\n",
    "Any dataset that does not meet this definition is considered \"messy\". \n",
    "\n",
    "### First example of messy data\n",
    "\n",
    "Messy data can appear deceptively clean and tidy, especially if you have not been exposed to it before. Let's read in some data containing the average arrival delay of different airlines departing from different airports. The first column contains the airlines, with each subsequent column containing the arrival delay with the airport code as the column name.\n",
    "\n",
    "[1]: http://vita.had.co.nz/papers/tidy-data.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arrival_delay = pd.read_csv('../data/tidy/average_arrival_delay.csv')\n",
    "arrival_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's wrong?\n",
    "\n",
    "Even though the dataset returns perfectly readable and acceptable information, it is not technically a tidy data set. Generally speaking, it is easier to perform further analysis on a tidy dataset than other datasets. The chapter titled \"Why Tidy Data?\" covers several examples comparing messy to tidy data to show the difference.\n",
    "\n",
    "The main issue with the above dataset is that some of the column names are variable values themselves. At this point, you might be confused as to what exactly is meant by a 'variable'. A simple definition of a variable is **anything that is liable to change**.\n",
    "\n",
    "### What are the variable names?\n",
    "\n",
    "Only the `airline` column appears to be a variable name that is found directly in the DataFrame above. You must infer the others from the description of the data. The variables are:\n",
    "\n",
    "* airline\n",
    "* origin airport\n",
    "* average arrival delay\n",
    "\n",
    "### Actual Tidying\n",
    "\n",
    "To tidy, we need to make sure the three tidy rules are followed. Let's attempt to restructure our data so that we have a DataFrame containing the three columns we've identified as variables.\n",
    "\n",
    "* The airlines are already in a single column\n",
    "* The origin airports are column names and need to be transposed into a single column\n",
    "* The average arrival delay is tiled across the rows\n",
    "\n",
    "## Melting\n",
    "\n",
    "The `melt` DataFrame method can take columns and stack them one-by-one on top of each other. It has two important parameters: \n",
    "\n",
    "* `id_vars` - a list (or single string) of column names that you want to keep as columns.\n",
    "* `value_vars` - a list (or single string) of column names that you would like to reshape into one column\n",
    "\n",
    "This 'reshaping' into one column is often referred to as **melting**, **stacking**, or **unpivoting**. The `id_vars` columns will remain in the same columns they currently reside, but **repeat** to align with all the newly melted values in the `value_vars` columns. Let's keep the `airline` column vertical and melt the origin airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = ['ATL', 'IAH', 'LAX', 'SFO']\n",
    "ad_melted = arrival_delay.melt(id_vars='airline', value_vars=airports)\n",
    "ad_melted.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns with `var_name` and `value_name`\n",
    "\n",
    "By default, the `melt` method names the column containing the old column names as `variable` and the values of these columns is named `value`. Two additional parameters, `var_name` and `value_name`, are provided to set these column names to specific values.\n",
    "\n",
    "### `value_vars` is optional\n",
    "\n",
    "By default, `melt` will melt all the columns that are not `id_vars`. You don't have to explicitly put them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_melted = arrival_delay.melt(id_vars='airline', \n",
    "                               var_name='origin_airport', \n",
    "                               value_name='avg_arrival_delay')\n",
    "ad_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing column stacking in `melt`\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/melt.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first tidy dataset\n",
    "\n",
    "By ensuring that each variable forms its own column, each observation is also in its own row. We now have tidy data.\n",
    "\n",
    "### Key terms - reshaping and restructuring\n",
    "\n",
    "When you think of tidy data, your brain should think about the terms **reshaping** or **restructuring**. The data is being maneuvered like a jigsaw puzzle. The actual data values are not changing (though some aspects of tidy data will change the values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Read in the movie dataset. Select the title column and all of the actor name columns. Restructure the dataset so that there are only three variables - the title of the movie, the actor number (1, 2, or 3), and the actor name. Sort the result by title and output the result.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Using the original movie dataset (and keeping its structure), attempt to count the total appearances of each actor in the dataset regardless whether they are 1, 2, or 3. Then repeat this task with your tidy dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the `tidy/employee_messy1.csv` file. It contains the count of all employees by race and gender.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the `tidy/employee_messy2.csv` file. It contains the count of all employees by department, race and gender.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Tidy the dataset in the `tidy/employee_salary_stats.csv` file. Save the tidy dataset to a variable and then select all the median salaries. The select all the median salaries with the original 'messy' dataset. Which one is easier to read summary statistics from?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
