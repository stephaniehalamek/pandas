{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DataFrames\n",
    "\n",
    "In the previous part, we covered the most common and fundamental attributes and methods for a Series. This chapter begins our coverage of similar and analogous operations for DataFrames.\n",
    "\n",
    "## DataFrames vs Series\n",
    "\n",
    "DataFrames and Series are extremely similar objects. A Series is just a single dimension of data and is usually formed from a single column of a DataFrame. Series have an index and values, but no columns. A DataFrame can be thought of as columns of Series objects each directly accessible by placing the column name within *just the brackets*.\n",
    "\n",
    "### View the API for a complete list of functionality\n",
    "\n",
    "As we did for Series, it can be helpful to see the entire list of attributes and methods available to DataFrames. Visit the [DataFrame section][1] of the API to see all of its functionality.\n",
    "\n",
    "### Best of DataFrame API\n",
    "\n",
    "DataFrames have an abundance of attributes and methods that do not give any additional functionality to the library. We focus on the core attributes and methods that give you the most power to complete a data analysis.\n",
    "\n",
    "### Minimally Sufficient Pandas\n",
    "\n",
    "As a gentle reminder, it is my opinion that you stick with a minimal subset of pandas when doing an analysis. Using more obscure methods does not make you a better analyst. The point of a data analysis is to clearly expose the information held within the data. Just about everything that you want to do can be clearly expressed with minimal pandas syntax.\n",
    "\n",
    "### Bikes dataset\n",
    "\n",
    "We will use the bikes dataset to introduce the core attributes and methods of DataFrames.\n",
    "\n",
    "[1]: http://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-30 14:43:00</td>\n",
       "      <td>2013-06-30 15:01:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender           starttime            stoptime  tripduration  \\\n",
       "0   Male 2013-06-28 19:01:00 2013-06-28 19:17:00           993   \n",
       "1   Male 2013-06-28 22:53:00 2013-06-28 23:03:00           623   \n",
       "2   Male 2013-06-30 14:43:00 2013-06-30 15:01:00          1040   \n",
       "\n",
       "              from_station_name  start_capacity          to_station_name  \\\n",
       "0     Lake Shore Dr & Monroe St            11.0    Michigan Ave & Oak St   \n",
       "1  Clinton St & Washington Blvd            31.0     Wells St & Walton St   \n",
       "2  Sheffield Ave & Kingsbury St            15.0  Dearborn St & Monroe St   \n",
       "\n",
       "   end_capacity  temperature  wind_speed        events  \n",
       "0          15.0         73.9        12.7  mostlycloudy  \n",
       "1          19.0         69.1         6.9  partlycloudy  \n",
       "2          23.0         73.0        16.1  mostlycloudy  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('../data/bikes.csv', parse_dates=['starttime', 'stoptime'])\n",
    "bikes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core DataFrame attributes\n",
    "\n",
    "The core DataFrame attributes that you need to know are listed below.\n",
    "\n",
    "* `index`\n",
    "* `columns`\n",
    "* `values`\n",
    "* `dtypes`\n",
    "* `shape`\n",
    "* `size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the index and columns\n",
    "\n",
    "We've discussed the index and columns extensively before this chapter. As a review, the purpose of the index is to label each row, just as the the purpose of the columns is to label each column. The index and columns are not data. They are labels for the data. If no index is set during read, pandas uses the default `RangeIndex` which defines a sequence of consecutive integers beginning at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=50089, step=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's access the column names with the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `values` returns a 2-D numpy array\n",
    "\n",
    "The `values` attribute returns a two-dimensional numpy array of all the column values. It is like a DataFrame with no index or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced discussion on the `values` attribute\n",
    "\n",
    "The `values` attribute always returns a single numpy array, which may lead you to believe that pandas stores its data as a single numpy array. This isn't the case. pandas has separate two-dimensional numpy arrays for each data type in the DataFrame. For instance, if a DataFrame contains integers, floats, strings, and datetimes, then pandas will have four separate numpy arrays to contain data for each of those data types. The reason for this, is that numpy arrays can only be of one specific data type. In other words, numpy arrays contain **homogeneous** data. The exception to this is the 'object' numpy data type which can contain any Python object.\n",
    "\n",
    "Whenever you access the `values` attribute of a DataFrame, pandas concatenates together all of the numpy arrays together to return a single array. Notice that the data type of the resulting `bikes.values` array is object. This is because the `bikes` DataFrame contains string columns and the only valid numpy data type that allows both numeric and string values is object.\n",
    "\n",
    "If you had a DataFrame consisting only of integers and floats, then the `values` attribute would return an array with a data type of float. pandas always chooses the data type that loses no information when you access the `values` attribute. Below, an integer column (`tripduration`) and a float column (`start_capacity`) are selected and then the `values` attribute is accessed to return a numpy array with a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes[['tripduration', 'start_capacity']].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` returns a tuple of the number of rows and columns\n",
    "\n",
    "The `shape` attribute returns a Python tuple of length 2 containing the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = bikes.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the number of rows or columns as an integer by selecting them from the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't necessary to assign the tuple to a variable beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `size` returns the total number of elements in the DataFrame\n",
    "\n",
    "The `size` attribute is a bit tricky and returns the total number of elements in the DataFrame. This is simply the number of rows multiplied by the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this by multiplying the number of rows and columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape[0] * shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `len` function returns the number of rows\n",
    "\n",
    "Passing in the DataFrame to the built-in Python `len` function returns the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic DataFrame operations\n",
    "\n",
    "We now cover the arithmetic operators `+`, `-`, `*`, `/`, `**`, `//`, `%` on a DataFrame. Let's say we have DataFrame, `df`, and execute `df + 5`. pandas attempts to add 5 to each value in the DataFrame. This operation only completes if all the columns are numeric (or boolean).\n",
    "\n",
    "### Attempt to add 5 to bikes\n",
    "\n",
    "If we attempt to add 5 to `bikes` we get an error, as there are a mix of numeric, object, and datetime columns. Adding the integer 5 to a string or datetime columns is impossible and a `TypeError` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only numeric data with `select_dtypes`\n",
    "\n",
    "DataFrames have a method unique to them called `select_dtypes` which selects a subset of columns with the passed type. Pass it the data type you want to select as a string. For example, pass it the string `'int64'` to select all of the 64-bit integer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.select_dtypes('int64').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all of the 64-bit float columns by passing it the string `'float64'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes.select_dtypes('float64').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns from each data type may be selected in this manner. You can also select columns of multiple data types by using a list. Here, we select both 64-bit integers and floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bikes.select_dtypes(['int64', 'float64']).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integers and floats of different bit sizes are considered different data types and you will need to use their exact name to select them with this method. For instance, 'int16' selects all 16-bit integer columns. A deep dive into all of pandas data types is found in the **Data Types** part of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the string 'number' to select all numeric data\n",
    "\n",
    "pandas offers a shortcut to select all numeric data types (integers and floats) with the string 'number'. We assign this result to `bikes_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_number = bikes.select_dtypes('number')\n",
    "bikes_number.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 5 to `bikes_number`\n",
    "\n",
    "Now that we have a DataFrame consisting entirely of numeric data, we can successfully add 5 to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_number + 5).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition and multiplication with string columns\n",
    "\n",
    "Addition actually works with strings by appending the word being added to each value. You can also use multiplication to concatenate each string value to itself. We first select all of the string columns and assign the result to a new variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_strings = bikes.select_dtypes('object')\n",
    "bikes_strings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition operator can now be used to append a string to each value in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_strings + ' SOMESTRING').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the multiplication operator can be used with an integer to concatenate each string value to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_strings * 3).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame comparison operators\n",
    "\n",
    "The comparison operators (`<`, `<=`, `>`, `>=`, `==`, `!=`) work similarly to the arithmetic ones and return a DataFrame of all boolean columns. Here, we test whether every value in the DataFrame is greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bikes_number > 5).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap of DataFrame and Series methods\n",
    "\n",
    "Most of the methods that exist for Series also exist for DataFrames and vice-versa. This is good news as it would be a  hassle to have a different set of methods for such similar objects. In this section, we find all the attributes and methods that are either in-common or unique to Series and DataFrames. We begin by using a set comprehension to get all of the public (those that don't begin with an underscore) attributes and methods for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public = {method for method in dir(pd.DataFrame) \n",
    "             if not method.startswith('_')}\n",
    "series_public = {method for method in dir(pd.Series) \n",
    "                 if not method.startswith('_')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's output the total number of methods for each type. Notice how they have nearly the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_public), len(series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the number of methods in common. The ampersand computes the intersection between sets. About 90% of the attributes and methods are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_public & series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes and methods unique to DataFrames\n",
    "\n",
    "The minus sign computes the difference between one set and another. It returns all of the elements unique to the first set. Below we return the attributes and methods unique to DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_public - series_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes and methods unique to Series\n",
    "\n",
    "Reversing the operation returns the attributes and methods unique to Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(series_public - df_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionaries\n",
    "\n",
    "A data dictionary is an important element of a data analysis and at a minimum gives us the column name and description of each column. Other information on each column can be kept in it such as the data type of each column or number of missing values.\n",
    "\n",
    "The college dataset has a data dictionary available that can be read in as a DataFrame. It contains the descriptions of each column, which is important with this dataset, as the column names are not easily decipherable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are more than 20 (the default) columns\n",
    "pd.set_option('display.max_columns', 40) \n",
    "college = pd.read_csv('../data/college.csv', index_col='instnm')\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary is a CSV, which can be read in as a DataFrame to help understand the information in the college DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv('../data/dictionaries/college_data_dictionary.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span  style=\"color:green; font-size:16px\">Select only the 64-bit float columns from the `college` DataFrame. How many are there?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">When you call the `info` method on a DataFrame, one of the very last items that gets outputted is the count of columns for each data type. Can you think of a different combination of pandas operations that would return this as a Series.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
